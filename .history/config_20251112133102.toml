[llm]
base_url = "http://127.0.0.1:8080/v1"   # your OpenAI-compatible server (llama.cpp, vLLM, TGI, etc.)
model    = "numind/NuExtract-2.0-8B"    # NuMind model (8B as requested)
api_key  = "sk-local"                   # usually ignored by local servers
use_grammar = false                    # set false if your server doesn't support 'grammar'
max_tokens = 256
temperature = 0.0                       # NuExtract recommends ~0

[pdf]
path = "data/dys064.pdf"
max_pages = 20

[task]
name = "n_included"                     # extraction task

[logging]
level = "INFO"
